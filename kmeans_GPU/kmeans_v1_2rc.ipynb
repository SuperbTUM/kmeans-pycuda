{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kmeans_v1.2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FImZ1pKmxjWN",
        "outputId": "6a2e870b-1978-4934-9fb9-90508eb30f70"
      },
      "source": [
        "!pip install pycuda ThrustRTC scikit-cuda"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2021.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 7.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ThrustRTC\n",
            "  Downloading ThrustRTC-0.3.15-py3-none-any.whl (765 kB)\n",
            "\u001b[K     |████████████████████████████████| 765 kB 52.7 MB/s \n",
            "\u001b[?25hCollecting scikit-cuda\n",
            "  Downloading scikit_cuda-0.5.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[K     |████████████████████████████████| 114 kB 74.8 MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "  Downloading pytools-2021.2.8.tar.gz (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako\n",
            "  Downloading Mako-1.1.5-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (1.19.5)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from ThrustRTC) (1.14.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (2.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->ThrustRTC) (2.20)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2021.1-cp37-cp37m-linux_x86_64.whl size=627251 sha256=dea5050e9574800e285f06f68c9ab28f534c097f49dd42a57e6fb882ea519e60\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/ef/49/dc6a5feb8d980b37c83d465ecab24949a6aa19458522a9e001\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2021.2.8-py2.py3-none-any.whl size=60725 sha256=8301e26d0ce1b2ca902ae851d5e94954859f315d35f8640b39e19ea749c365b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/2d/ef/0127a17bafa44971f11d05d0e38d7947144cf9e33313bf12a7\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: pytools, mako, pycuda, ThrustRTC, scikit-cuda\n",
            "Successfully installed ThrustRTC-0.3.15 mako-1.1.5 pycuda-2021.1 pytools-2021.2.8 scikit-cuda-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-5xeYB3a89o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6738555-b669-4d6f-8bff-619421c0eee6"
      },
      "source": [
        "!pip install fsspec"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec\n",
            "  Downloading fsspec-2021.10.1-py3-none-any.whl (125 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 38.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20 kB 39.7 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 23.2 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 92 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 112 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 122 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 125 kB 9.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: fsspec\n",
            "Successfully installed fsspec-2021.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa1sQ4QvgKtw",
        "outputId": "1101176e-98fc-40e5-8bc9-e11d756bc379"
      },
      "source": [
        "!pip install --upgrade tbb"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tbb\n",
            "  Downloading tbb-2021.4.0-py2.py3-none-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 10.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: tbb\n",
            "Successfully installed tbb-2021.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnrNPbWlmNE_",
        "outputId": "5139d0b6-ac81-45c1-e61c-d6e7d859fa6f"
      },
      "source": [
        "!pip install MulticoreTSNE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MulticoreTSNE\n",
            "  Downloading MulticoreTSNE-0.1.tar.gz (20 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from MulticoreTSNE) (1.19.5)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from MulticoreTSNE) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->MulticoreTSNE) (2.20)\n",
            "Building wheels for collected packages: MulticoreTSNE\n",
            "  Building wheel for MulticoreTSNE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for MulticoreTSNE: filename=MulticoreTSNE-0.1-cp37-cp37m-linux_x86_64.whl size=68518 sha256=78d0ca21b7f948d3d402d11bbc0ce1400e272e239ae6afcc5b124702958d11f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/47/df/c0d66e9f775f33281c422a1964de86a59c47f93bb8c37643e3\n",
            "Successfully built MulticoreTSNE\n",
            "Installing collected packages: MulticoreTSNE\n",
            "Successfully installed MulticoreTSNE-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNqgSMNpxpMZ",
        "outputId": "c18fae9a-ff0a-4535-df44-d8a66130d3ee"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7ZiYfAjyEnA",
        "outputId": "de67dd73-1e68-4cbf-e003-cf5cf5ec8816"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "path = \"/content/drive/My Drive\"\n",
        "sys.path.append(path)\n",
        "os.chdir(path)\n",
        "%cd graduation\\ project/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/graduation project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhCCT4JjuI0b",
        "outputId": "e333a770-87b7-468c-e759-d8e33985c0f8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 28 15:01:31 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.29.05    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OleEcnNNxjtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c1a9126-2ab4-4a95-94f9-8fb2dff36836"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skcuda import cublas\n",
        "from pycuda import gpuarray\n",
        "import pycuda.autoinit\n",
        "import time\n",
        "from pycuda.compiler import SourceModule\n",
        "import pycuda.driver as cuda\n",
        "import ThrustRTC as trtc\n",
        "import numpy as np\n",
        "import time\n",
        "from matplotlib import pyplot\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "import random\n",
        "import numba\n",
        "\n",
        "FLOAT_MAX = 1e10"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/skcuda/cublas.py:284: UserWarning: creating CUBLAS context to get version number\n",
            "  warnings.warn('creating CUBLAS context to get version number')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkFQasqzDWJO"
      },
      "source": [
        "## Kernel function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obMPmIvsyDop"
      },
      "source": [
        "# 求平方\n",
        "get_square = SourceModule(\n",
        "'''\n",
        "__global__ void x_square(const float* __restrict__ x, float *output, int n)\n",
        "{\n",
        "    const int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if(idx<n)\n",
        "        output[idx] = x[idx] * x[idx];\n",
        "}\n",
        "\n",
        "__global__ void y_square(const float* __restrict__ y, float *output, int m)\n",
        "{\n",
        "    const int idx = threadIdx.x;\n",
        "    if(idx<m)\n",
        "        output[idx] = y[idx] * y[idx];\n",
        "}\n",
        "'''\n",
        ")\n",
        "\n",
        "# 求和\n",
        "square_sum = SourceModule(\n",
        "'''\n",
        "\n",
        "__global__ void sum_row_xy(float *s_x, float *s_y, float *self_sum1, float *self_sum2, int numSample, int k, int dim)\n",
        "{\n",
        "    const int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    \n",
        "    if(idx < k)\n",
        "        for(int i=0;i<dim;i++)\n",
        "            self_sum2[idx] += s_y[idx*dim+i];\n",
        "\n",
        "\n",
        "    if(idx < numSample + k && idx >= k)    \n",
        "        for(int j=0;j<dim;j++)    \n",
        "            self_sum1[idx - k] += s_x[(idx - k)*dim+j];    \n",
        "    \n",
        "    //__syncthreads(); \n",
        "}\n",
        "\n",
        "\n",
        "__global__ void sum_total(const float* __restrict__ self_sum1, const float* __restrict__ self_sum2, float *result, int k, int numSample)\n",
        "{\n",
        "    const int idx1 = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int quo = idx1 % numSample;\n",
        "    int rem = idx1 / numSample;\n",
        "    \n",
        "    if(idx1 < numSample * k)\n",
        "        result[idx1] = self_sum1[quo] + self_sum2[rem];\n",
        "     \n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void sum_row_x(float *s_x, float *self_sum1, int numSample, int dim){\n",
        "    const int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if(idx < numSample)\n",
        "        for(int j=0;j<dim;j++)    \n",
        "            self_sum1[idx] += s_x[idx*dim+j]; \n",
        "    //__syncthreads();\n",
        "}\n",
        "\n",
        "__global__ void sum_row_x_reduction(float *s_x, float *self_sum1, int numSample, int dim){\n",
        "    const int idx = blockIdx.x;\n",
        "    int tid = threadIdx.x;  // 42 * 8\n",
        "    __shared__ float s_xdata[1024];\n",
        "    s_xdata[tid] = s_x[tid + dim*idx];\n",
        "    __syncthreads();\n",
        "    for(int i=16; i>0; i >>= 1){\n",
        "      if(tid < i) s_xdata[tid] += s_xdata[tid+i];\n",
        "      __syncthreads();\n",
        "    }\n",
        "    // if (tid < 32) warpReduce(s_xdata, tid);\n",
        "    if(tid == 0){\n",
        "      self_sum1[idx] = s_xdata[0]; \n",
        "      for(int j=32; j < dim; j++)\n",
        "        self_sum1[idx] += s_xdata[j]; \n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "__device__ void warpReduce(volatile float* sdata,int tid) {\n",
        "    sdata[tid] += sdata[tid + 32];\n",
        "    sdata[tid] += sdata[tid + 16];\n",
        "    sdata[tid] += sdata[tid + 8];\n",
        "    sdata[tid] += sdata[tid + 4];\n",
        "    sdata[tid] += sdata[tid + 2];\n",
        "    sdata[tid] += sdata[tid + 1];\n",
        "}\n",
        "\n",
        "__global__ void sum_row_y_reduction(float *s_y, float *self_sum2, int dim){\n",
        "    const int idx = blockIdx.x;\n",
        "    int tid = threadIdx.x;\n",
        "    __shared__ float s_ydata[1024];\n",
        "    s_ydata[tid] = s_y[tid + dim*idx];\n",
        "    __syncthreads();\n",
        "    for(int i=16; i>0; i >>= 1){\n",
        "      if(tid < i) s_ydata[tid] += s_ydata[tid+i];\n",
        "      __syncthreads();\n",
        "    }\n",
        "    // if (tid < 16) warpReduce(s_ydata, tid);\n",
        "    if(tid == 0){\n",
        "      self_sum2[idx] = s_ydata[0]; \n",
        "      for(int j=32; j < dim; j++)\n",
        "        self_sum2[idx] += s_ydata[j]; \n",
        "    }\n",
        "    \n",
        "    \n",
        "}\n",
        "\n",
        "'''\n",
        ")\n",
        "\n",
        "\n",
        "# shared_memory.max()=48KB(12000 int/float32)\n",
        "find = SourceModule(\n",
        "'''\n",
        "__global__ void find_range(float *cluster, float *result)\n",
        "{\n",
        "    __shared__ float sdata[512];\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = blockIdx.x*blockDim.x+ threadIdx.x;\n",
        "    sdata[tid] = cluster[i];\n",
        "    __syncthreads();\n",
        "    if(sdata[tid] != sdata[tid+1] and tid < 499) // 统计各簇中元素的个数\n",
        "        result[int(sdata[tid])] = i+1;\n",
        "}\n",
        "\n",
        "'''\n",
        ")\n",
        "\n",
        "find_minimum = SourceModule(\n",
        "'''\n",
        "__global__ void find_min(const float* __restrict__ list, float *result_value, int *result_idx, int length, int n)\n",
        "{\n",
        "    __shared__ float sdata[1024];\n",
        "    __shared__ int ssdata[1024];\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;   \n",
        "\n",
        "\n",
        "    if(tid < length-1)\n",
        "    {\n",
        "        sdata[tid] = list[i + tid * length]; // store data\n",
        "        ssdata[tid] = tid; // store index\n",
        "    }\n",
        "    sdata[length - 1] = 10000;\n",
        "    ssdata[length - 1] = 23;  \n",
        "\n",
        "    __syncthreads();\n",
        "    \n",
        "    unsigned int s;\n",
        "    if(tid < length)\n",
        "    {\n",
        "        for(s = (blockDim.x+1)/2; s>0; s>>=1) {\n",
        "            if (tid < s) \n",
        "            {\n",
        "                ssdata[tid] = (sdata[tid] <= sdata[tid + s])? ssdata[tid]:ssdata[tid+s];\n",
        "                __syncthreads();\n",
        "                sdata[tid] = (sdata[tid] <= sdata[tid + s])? sdata[tid]:sdata[tid+s];\n",
        "                __syncthreads();\n",
        "            }\n",
        "\n",
        "            //__syncthreads();\n",
        "\n",
        "}\n",
        "        if(s == 0)\n",
        "        {\n",
        "            ssdata[0] = (sdata[0] <= sdata[n-1])? ssdata[0]:ssdata[n-1];\n",
        "            sdata[0] = (sdata[0] <= sdata[n-1])? sdata[0]:sdata[n-1];\n",
        "            //__syncthreads();\n",
        "        }    \n",
        "    }\n",
        "       \n",
        "    if(tid == 0)\n",
        "    {\n",
        "        result_idx[blockIdx.x] = ssdata[0];\n",
        "        result_value[blockIdx.x] = sdata[0];     \n",
        "    }\n",
        "}\n",
        "'''\n",
        ")\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6HB6jGRDdmS"
      },
      "source": [
        "## test for the kernels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrayA1cStRlD",
        "outputId": "0d085908-62cf-42f7-c592-7bd19f2d5975"
      },
      "source": [
        "## test\n",
        "s_y = np.ones((23, 41)).astype(np.float32).flatten()\n",
        "s_y[0] = 2\n",
        "s_y[41] = 4\n",
        "s_y[42] = 5\n",
        "s_y[-1] = 3\n",
        "s_y = gpuarray.to_gpu(s_y)\n",
        "sum2 = np.zeros((23, )).astype(np.float32)\n",
        "sum2 = gpuarray.to_gpu(sum2)\n",
        "k = np.int32(23)\n",
        "\n",
        "dim = np.int32(41)\n",
        "\n",
        "test = square_sum.get_function(\"sum_row_y_reduction\")\n",
        "# test = square_sum.get_function(\"sum_row_x\")\n",
        "test(s_y, sum2, dim, block=(41,1,1), grid=(23,1,1))\n",
        "# test(s_y, sum2, k_gpu, dim_gpu, block=(1024,1,1), grid=(1,1,1))\n",
        "sum2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([42., 48., 41., 41., 41., 41., 41., 41., 41., 41., 41., 41., 41.,\n",
              "       41., 41., 41., 41., 41., 41., 41., 41., 41., 43.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS7pesKZy_eT"
      },
      "source": [
        "# matrix1 is dataset, matrix2 is centroids\n",
        "def get_x_square(matrix1, numSample, dim):\n",
        "    \"\"\"\n",
        "      It can be interpolated that the dataset square need to calculate for only once!\n",
        "    \"\"\"\n",
        "    n = numSample * dim\n",
        "    grid_dim = int(np.ceil(n / 1024))\n",
        "    n = np.int32(n)\n",
        "\n",
        "    x = matrix1.flatten()\n",
        "    output_x = np.empty_like(x)\n",
        "    \n",
        "    x_gpu = gpuarray.to_gpu_async(x)\n",
        "    output_x_gpu = gpuarray.to_gpu_async(output_x)\n",
        "    x_func = get_square.get_function(\"x_square\")\n",
        "    \n",
        "    # we have a flexible block assignment\n",
        "    x_func(x_gpu, output_x_gpu, n, block=(1024,1,1), grid=(grid_dim,1))\n",
        "    return output_x_gpu # could be used as matrix1 in get_xy_square\n",
        "\n",
        "def get_xy_square(x_gpu, matrix2, cluster_k, numSample, dim):\n",
        "    m = cluster_k * dim\n",
        "    # determining grid size\n",
        "    m = np.int32(m)\n",
        "    \n",
        "    grid_dim = int(np.ceil(m / 1024))\n",
        "\n",
        "    output_y = np.zeros(matrix2.shape)\n",
        "\n",
        "    output_y_gpu = gpuarray.to_gpu_async(output_y)\n",
        "    y_func = get_square.get_function(\"y_square\")\n",
        "    \n",
        "    y_func(matrix2, output_y_gpu, m, block=(1024,1,1), grid=(grid_dim,1))\n",
        "\n",
        "    self_sum1 = np.zeros((numSample, ), dtype = np.float32)\n",
        "    self_sum2 = np.zeros((cluster_k, ), dtype = np.float32)\n",
        "    \n",
        "    self_sum1_gpu = gpuarray.to_gpu_async(self_sum1)\n",
        "    self_sum2_gpu = gpuarray.to_gpu_async(self_sum2)\n",
        "    \n",
        "    numSample_np = np.int32(numSample)\n",
        "    k = np.int32(cluster_k)\n",
        "    dim_ = np.int32(dim)\n",
        "\n",
        "    result = np.zeros((cluster_k*numSample, ), dtype = np.float32)\n",
        "    block_dim_result = len(result) // 1024 + 1\n",
        "    \n",
        "    result_gpu = gpuarray.to_gpu_async(result)\n",
        "   \n",
        "    # optimization v1.0\n",
        "\n",
        "    grid_dim_new = int(np.ceil(numSample / 1024))\n",
        "    sum_func_y = square_sum.get_function('sum_row_y_reduction')\n",
        "    sum_func_y(output_y_gpu, self_sum2_gpu, dim_, block=(dim, 1, 1), grid=(cluster_k, 1, 1))\n",
        "\n",
        "    sum_func_x = square_sum.get_function('sum_row_x')\n",
        "    sum_func_x(x_gpu, self_sum1_gpu, numSample_np, dim_, block=(1024, 1, 1), grid=(grid_dim_new, 1, 1))\n",
        "\n",
        "    sum_func_total = square_sum.get_function(\"sum_total\")\n",
        "    sum_func_total(self_sum1_gpu, self_sum2_gpu, result_gpu, k, numSample_np, block=(1024,1,1), grid=(block_dim_result,1))\n",
        "    \n",
        "    return result_gpu # result_gpu could be used for matrix3 in dis_computation\n",
        "\n",
        "\n",
        "# 计算与质心之间的距离\n",
        "def dis_computation(matrix1, matrix2, matrix3, orishape_matrix1):\n",
        "    \"\"\"matrix 1 is centroids, \n",
        "    matrix 2 is dataset.T, \n",
        "    matrix 3 is result\"\"\"\n",
        "    \n",
        "    m = orishape_matrix1[0]\n",
        "    n = matrix2.shape[1]\n",
        "    \n",
        "    k = orishape_matrix1[1]\n",
        "    B_gpu = matrix1\n",
        "    #the above is matrix B\n",
        "\n",
        "    A_gpu = matrix2\n",
        "    # the above is matrix A\n",
        "    transa = 'n'\n",
        "    transb = 'n'\n",
        "    alpha = -2\n",
        "    beta = 1\n",
        "    # computing matrix\n",
        "    h = cublas.cublasCreate()\n",
        "    cublas.cublasSgemm(h, transa, transb, n, m, k, alpha, A_gpu.gpudata, n, B_gpu.gpudata, k, beta, matrix3.gpudata, n)\n",
        "    cublas.cublasDestroy(h)\n",
        "    \n",
        "    C = matrix3.get_async()\n",
        "    return C\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zP5RbDGDlyw"
      },
      "source": [
        "## Cluster assignment of all kinds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1efMUbdhDhw9"
      },
      "source": [
        "def cluster_assignment(C, k=23, numSample=494021):\n",
        "    C = np.reshape(C, (k, numSample))\n",
        "    minDist = np.amin(C, axis = 0)\n",
        "    minDistIdx = np.argmin(C, axis=0)\n",
        "    cluster_assignment = np.vstack((minDistIdx, minDist)).T\n",
        "    return cluster_assignment\n",
        "\n",
        "\n",
        "\n",
        "def sort_by_key_without_count(clusterAssment):\n",
        "    cluster = clusterAssment[:,0].astype(np.float32)\n",
        "    cluster_gpu = trtc.device_vector_from_numpy(cluster)\n",
        "    n = cluster_gpu.size()\n",
        "    index = trtc.device_vector(\"int32_t\", n)\n",
        "    trtc.Sequence(index)\n",
        "    trtc.Sort_By_Key(cluster_gpu, index)\n",
        "    index_cpu = index.to_host()\n",
        "    cluster_cpu = cluster_gpu.to_host()\n",
        "    return index_cpu, cluster_cpu\n",
        "\n",
        "\n",
        "def sort_gpu(index_cpu, cluster_cpu, dataset, k, placement):\n",
        "    cluster1 = cluster_cpu[0:250000].astype(np.float32)\n",
        "    cluster2 = cluster_cpu[250000:-1].astype(np.float32)\n",
        "    result1 = np.zeros((k-1,),dtype=np.float32)\n",
        "    result2 = np.zeros((k-1,),dtype=np.float32)\n",
        "    find_func = find.get_function(\"find_range\")\n",
        "    find_func(cuda.In(cluster1),cuda.Out(result1), block=(500,1,1),grid=(500,1))\n",
        "    find_func(cuda.In(cluster2),cuda.Out(result2), block=(500,1,1),grid=(500,1))\n",
        "    # 取置信值，这里的代码可以优化一下\n",
        "    # 如果数据量控制在25w以内效果最佳\n",
        "    for j in range(len(result2)):\n",
        "        if(result2[j] != 0):\n",
        "            result2[j] += 250000 # 分批处理，第一批计数从0开始，第二批从250000开始\n",
        "    for i in range(len(result2)-1):\n",
        "        if(result2[i] > result2[i+1]): # 消除异常值\n",
        "            result2[i] = 0\n",
        "    starting_points = [0]\n",
        "    for jj in range(len(result2)):\n",
        "        starting_points.append(max(result1[jj], result2[jj]))\n",
        "    starting_points.append(dataset.shape[0]+1)\n",
        "    data_in_cluster = []\n",
        "    start = int(starting_points[placement])\n",
        "    end = int(starting_points[placement+1])\n",
        "    data_in_cluster = dataset[index_cpu[start:end],:]\n",
        "    data_in_cluster = np.array(data_in_cluster)\n",
        "    return data_in_cluster\n",
        "\n",
        "\n",
        "\n",
        "def cluster_assignment_gpu(C):\n",
        "    C = C.astype(np.float32)\n",
        "    length = np.int32(C.shape[1])\n",
        "    result = np.zeros((C.shape[0],), dtype = np.float32)\n",
        "    # 找到距离最近的质心点\n",
        "    find_func = find.get_function(\"find_minimum\")\n",
        "    find_func(gpuarray.to_gpu(C),gpuarray.to_gpu(result),length,block=(C.shape[1],1,1),grid=(C.shape[0],1))\n",
        "    \n",
        "    result_idx = np.argmin(C, axis = 1)    \n",
        "    cluster_assignment = np.zeros((len(result_idx),2))\n",
        "    cluster_assignment[:,0] = result_idx\n",
        "    cluster_assignment[:,1] = result\n",
        "    return cluster_assignment\n",
        "\n",
        "\n",
        "@numba.njit(nogil=True, cache=True)\n",
        "def trans(C):\n",
        "    C = np.reshape(C, (k, numSample))\n",
        "    C = C.T\n",
        "    return C.flatten()\n",
        "\n",
        "\n",
        "def cluster_assignment_new(C, k, numSample=494021):\n",
        "    C = C.reshape((numSample, k), order=\"F\")\n",
        "    C = C.flatten()\n",
        "    lengthC = k * numSample\n",
        "    n = k    \n",
        "    divider = k + 1 if(k % 2) else k        \n",
        "    while(divider % 2 == 0):\n",
        "        n = divider / 2\n",
        "        divider /= 2\n",
        "    n = np.int32(n)\n",
        "    \n",
        "    length = np.int32(k+1)\n",
        "    \n",
        "    result_value = gpuarray.to_gpu(np.zeros((lengthC // k, ), dtype = np.float32))\n",
        "    result_idx = gpuarray.to_gpu(np.zeros((lengthC // k, ), dtype = np.int32))\n",
        "    C = gpuarray.to_gpu(C)\n",
        "\n",
        "    find_func_hybrid = find_minimum.get_function(\"find_min\")\n",
        "    find_func_hybrid(C, result_value, result_idx, length, n, block=(k, 1, 1),grid=(lengthC // k, 1))\n",
        "    cluster_assignment = np.zeros((len(result_idx),2))\n",
        "    \n",
        "    cluster_assignment[:,0] = result_idx.get()\n",
        "    cluster_assignment[:,1] = result_value.get()\n",
        "    return cluster_assignment"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx_PNqgxDsnd"
      },
      "source": [
        "## main function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDdfrH3DzVCm"
      },
      "source": [
        "import pycuda\n",
        "\n",
        "\n",
        "# cpu的版本\n",
        "def euclDistance(vector1,vector2):\n",
        "    return np.sqrt(sum(np.power(vector2-vector1, 2))) #power计算次方\n",
        "\n",
        "##初始化数据的中心点，k表示聚类中心数\n",
        "##随机生成k个聚类中心\n",
        "@numba.njit(nogil=True, cache=True, parallel=True)\n",
        "def initCentroids(dataset, k):\n",
        "    dim = dataset.shape[1]\n",
        "    centroids = np.zeros((k,dim), dtype=np.float32)\n",
        "    for i in range(1,k+1):\n",
        "        #index=int(np.random.uniform(0,numSample))#随机生成数\n",
        "        index = int(i*10000)\n",
        "        centroids[i-1,:] = dataset[index,:]\n",
        "    return centroids\n",
        "\n",
        "\n",
        "@numba.njit(nogil=True, parallel=True, cache=True)\n",
        "def comparison(a, b, numSample, stop_thres):\n",
        "    count = 0\n",
        "    for i in range(numSample):\n",
        "        if a[i] != b[i]:\n",
        "            count += 1\n",
        "            if count > stop_thres:\n",
        "                clusterChanged = True\n",
        "                break\n",
        "        else:\n",
        "            clusterChanged = False\n",
        "    return clusterChanged\n",
        "##kmean算法\n",
        "def kmeans(dataset, k):\n",
        "    pycuda.tools.clear_context_caches()\n",
        "    numSample, dim = dataset.shape\n",
        "    #生成新的两列数组，保存聚类信息\n",
        "    # 第一列表示所属聚类中心，第二列表示与中心的误差\n",
        "    clusterAssment = np.zeros((numSample, 2), dtype=np.int8)#这里dtype就默认\n",
        "    clusterChanged = True\n",
        "\n",
        "    ## step1 初始化聚类中心\n",
        "    centroids = initCentroids(dataset, k)\n",
        "    buffer = np.empty((numSample, ))\n",
        "    itr = 0\n",
        "    dataset_gpu = gpuarray.to_gpu_async(dataset.T)\n",
        "    dataset_gpu_square = get_x_square(dataset, numSample, dim)\n",
        "    orishape_matrix1 = centroids.shape\n",
        "    stop_thres = numSample // 10000\n",
        "    while itr < 28:\n",
        "        itr += 1\n",
        "        # clusterChanged = comparison(buffer, clusterAssment[:, 0], numSample, stop_thres)\n",
        "        count = 0\n",
        "        comparable_list = zip(buffer, clusterAssment[:, 0])\n",
        "\n",
        "        for val1, val2 in comparable_list:\n",
        "            if val1 != val2:\n",
        "                count += 1\n",
        "                if(count > stop_thres):\n",
        "                    clusterChanged = True\n",
        "                    break\n",
        "            else:\n",
        "                clusterChanged = False\n",
        "        if clusterChanged is False:\n",
        "            break\n",
        "        \n",
        "        buffer = clusterAssment[:, 0]\n",
        "        #二重循环：对所有数据点，与k个聚类中心计算距离\n",
        "        #并保存标签与距离\n",
        "        matrix1 = gpuarray.to_gpu_async(centroids.flatten())\n",
        "        matrix2 = dataset_gpu\n",
        "        matrix3 = get_xy_square(dataset_gpu_square, matrix1, k, numSample, dim)\n",
        "        distance_mat = dis_computation(matrix1, matrix2, matrix3, orishape_matrix1)  # matrix1: dataset, matrix2: centroids.T, matrix3: (dataset.shape[0], centroids.shape[0]) \n",
        "        clusterAssment = cluster_assignment_new(distance_mat, k, numSample)\n",
        "        ## step4 循环结束后更新聚类中心\n",
        "        \n",
        "        for i in range(k):\n",
        "            comp = np.nonzero(clusterAssment[:, 0] == i)[0] # 当前状态的聚类情况\n",
        "            # comp_buffer = np.nonzero(buffer[:, 0] == i)[0] # 上一状态的聚类情况\n",
        "            # if(np.array_equal(comp, comp_buffer)):\n",
        "            #     # 当前簇内元素没有改变？如果没有改变，下次聚类忽略该簇\n",
        "            #     continue\n",
        "            pointsInCluster = dataset[comp]\n",
        "            centroids[i, :] = np.mean(pointsInCluster, axis=0)\n",
        "    ##循环结束，返回聚类中心和标签信息\n",
        "    return centroids, clusterAssment"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMcusnOpzfYG",
        "outputId": "47f9419c-c31f-4ccc-e1fe-456f1fb5cf36"
      },
      "source": [
        "import dask.dataframe as dd\n",
        "import matplotlib.pyplot as plt \n",
        "from numba.core.errors import NumbaDeprecationWarning, NumbaPerformanceWarning\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
        "warnings.simplefilter('ignore', category=NumbaPerformanceWarning)\n",
        "\n",
        "\n",
        "@numba.njit(nogil=True, parallel=True, cache=True)\n",
        "def adjust(category, real, pre, numSample):\n",
        "    for j in range(numSample):\n",
        "        for nn in range(k):\n",
        "            if(category[j] == real[nn][0]):\n",
        "                category[j] = pre[nn][0]\n",
        "    return category\n",
        "\n",
        "def evaluation(category_pre, category, numSample):\n",
        "    real = Counter(category)\n",
        "    pre = Counter(category_pre)\n",
        "    print(\"Real category is \", sorted(real.values()))\n",
        "    print(\"Predicted clustering is \", sorted(pre.values()))\n",
        "    real = real.most_common()\n",
        "    pre = pre.most_common()\n",
        "    real = np.asarray(real)\n",
        "    pre = np.asarray(pre)\n",
        "    category = adjust(category, real, pre, numSample)\n",
        "    ARI = metrics.adjusted_rand_score(category, category_pre)\n",
        "    AMI = metrics.adjusted_mutual_info_score(category, category_pre)\n",
        "    print(\"The ARI value is {:.4f}\".format(ARI))\n",
        "    print(\"The AMI value is {:.4f}\".format(AMI))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ## load data\n",
        "    dataset = dd.read_csv('kdd_pre_final.csv',sep=',')\n",
        "    # 真实的标签\n",
        "    category_real = dataset.loc[:,[\"classification\"]]\n",
        " \n",
        "    dataset=dataset.iloc[:,:-2]  # This is because the last two columns are brief clustering (k=5) and detailed clustering (k=23)\n",
        "    dataset = np.asarray(dataset).astype(np.float32)\n",
        "    ##  k表示聚类中心数\n",
        "    k = 23\n",
        "    times = 10\n",
        "    start = time.time()\n",
        "    for _ in range(times):\n",
        "        centroids, clusterAssment = kmeans(dataset, k)\n",
        "    end = time.time()\n",
        "    print('algorithm (for training) average time: %.2f seconds'%((end - start) / times))\n",
        "    \n",
        "    category_real = np.asarray(category_real).astype(np.int8).flatten()\n",
        "    category_pre = np.array(clusterAssment[:, 0], dtype = np.int8)\n",
        "    evaluation(category_pre, category_real, dataset.shape[0])\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "algorithm (for training) average time: 5.28 seconds\n",
            "Real category is  [2, 3, 4, 7, 8, 9, 10, 12, 20, 21, 30, 53, 231, 264, 979, 1020, 1040, 1247, 1589, 2203, 97278, 107201, 280790]\n",
            "Predicted clustering is  [804, 904, 1352, 1930, 2169, 2241, 4565, 4853, 5196, 5333, 5602, 6617, 6700, 7453, 7628, 17196, 20520, 22603, 24397, 24850, 28373, 31143, 261592]\n",
            "The ARI value is 0.7531\n",
            "The AMI value is 0.6554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5StNxaL8ciDZ"
      },
      "source": [
        "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
        "\n",
        "\n",
        "d = dict()\n",
        "for i in range(k):\n",
        "    d[i] = np.nonzero(category_pre == i)[0] # 当前状态的聚类情况\n",
        "tsne = TSNE(n_jobs=4, n_components=2, perplexity=20) \n",
        "dataset_tsne = tsne.fit_transform(dataset) \n",
        "vis_x, vis_y = dataset_tsne[:,0], dataset_tsne[:,1]\n",
        "for key in d:\n",
        "    plt.scatter(vis_x[d[key]], vis_y[d[key]], cmap=plt.cm.get_cmap(\"jet\", k))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}