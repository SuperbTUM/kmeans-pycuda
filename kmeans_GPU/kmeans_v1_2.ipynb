{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kmeans_v1.1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FImZ1pKmxjWN",
        "outputId": "ead87785-2074-4746-80f7-f3b1fe9652ff"
      },
      "source": [
        "!pip install pycuda ThrustRTC scikit-cuda"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.7/dist-packages (2021.1)\n",
            "Requirement already satisfied: ThrustRTC in /usr/local/lib/python3.7/dist-packages (0.3.15)\n",
            "Requirement already satisfied: scikit-cuda in /usr/local/lib/python3.7/dist-packages (0.5.3)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.1.5)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.7/dist-packages (from pycuda) (2021.2.8)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (1.19.5)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from ThrustRTC) (1.14.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (2.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->ThrustRTC) (2.20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNqgSMNpxpMZ",
        "outputId": "9dc6b51e-990d-4b82-c6da-2a87695c1576"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7ZiYfAjyEnA",
        "outputId": "a7195c6e-4c09-4656-e9f8-6a49d4334961"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "path = \"/content/drive/My Drive\"\n",
        "sys.path.append(path)\n",
        "os.chdir(path)\n",
        "%cd graduation\\ project/"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/graduation project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhCCT4JjuI0b",
        "outputId": "a3ff6019-5820-4e28-8b28-80f195b49a81"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Oct  6 18:34:21 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    31W / 250W |   1330MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OleEcnNNxjtJ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skcuda import cublas\n",
        "from pycuda import gpuarray\n",
        "import pycuda.autoinit\n",
        "import time\n",
        "from pycuda.compiler import SourceModule\n",
        "import pycuda.driver as cuda\n",
        "import ThrustRTC as trtc\n",
        "import numpy as np\n",
        "import time\n",
        "from matplotlib import pyplot\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "FLOAT_MAX = 1e10"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obMPmIvsyDop"
      },
      "source": [
        "# 求平方\n",
        "get_square = SourceModule(\n",
        "'''\n",
        "__global__ void x_square(float *x, int &n)\n",
        "{\n",
        "    const int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if(idx<n)\n",
        "        x[idx] = x[idx] * x[idx];\n",
        "}\n",
        "\n",
        "__global__ void y_square(float *y, int &m)\n",
        "{\n",
        "    const int idx = threadIdx.x;\n",
        "    if(idx<m)\n",
        "        y[idx] = y[idx] * y[idx];\n",
        "\n",
        "}\n",
        "'''\n",
        ")\n",
        "\n",
        "# 求和\n",
        "square_sum = SourceModule(\n",
        "'''\n",
        "\n",
        "__global__ void sum_row_xy(float *s_x, float *s_y, float *self_sum1, float *self_sum2, int &numSample, int &k, int &dim)\n",
        "{\n",
        "    const int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    \n",
        "    if(idx < k)\n",
        "        for(int i=0;i<dim;i++)\n",
        "            self_sum2[idx] += s_y[idx*dim+i];\n",
        "\n",
        "\n",
        "    if(idx < numSample + k && idx >= k)    \n",
        "        for(int j=0;j<dim;j++)    \n",
        "            self_sum1[idx - k] += s_x[(idx - k)*dim+j];    \n",
        "    \n",
        "    __syncthreads(); \n",
        "}\n",
        "\n",
        "__global__ void sum_total(float *self_sum1, float *self_sum2, float *result, int &k, int &numSample)\n",
        "{\n",
        "    const int idx1 = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int quo = idx1 % numSample;\n",
        "    int rem = idx1 / numSample;\n",
        "    \n",
        "    if(idx1 < numSample * k)\n",
        "    \n",
        "        result[idx1] = self_sum1[quo] + self_sum2[rem];\n",
        "\n",
        "    __syncthreads();     \n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "'''\n",
        ")\n",
        "\n",
        "\n",
        "# shared_memory.max()=48KB(12000 int/float32)\n",
        "find = SourceModule(\n",
        "'''\n",
        "__global__ void find_range(float *cluster, float *result)\n",
        "{\n",
        "    __shared__ float sdata[512];\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = blockIdx.x*blockDim.x+ threadIdx.x;\n",
        "    sdata[tid] = cluster[i];\n",
        "    __syncthreads();\n",
        "    if(sdata[tid] != sdata[tid+1] and tid < 499) // 统计各簇中元素的个数\n",
        "        result[int(sdata[tid])] = i+1;\n",
        "    __syncthreads();\n",
        "}\n",
        "\n",
        "'''\n",
        ")\n",
        "\n",
        "find_minimum = SourceModule(\n",
        "'''\n",
        "__global__ void find_min(float *list, float *result_value, int *result_idx, int &length, int &n)\n",
        "{\n",
        "    __shared__ float sdata[1024];\n",
        "    __shared__ int ssdata[1024];\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;   \n",
        "\n",
        "\n",
        "    if(tid < length-1)\n",
        "    {\n",
        "        sdata[tid] = list[i]; // store data\n",
        "        ssdata[tid] = tid; // store index\n",
        "    }\n",
        "    sdata[length - 1] = 10000;\n",
        "    ssdata[length - 1] = 23;  \n",
        "\n",
        "    __syncthreads();\n",
        "    \n",
        "    unsigned int s;\n",
        "    if(tid < length)\n",
        "    {\n",
        "        for(s = (blockDim.x+1)/2; s>0; s>>=1) {\n",
        "            if (tid < s) \n",
        "            {\n",
        "                ssdata[tid] = (sdata[tid] <= sdata[tid + s])? ssdata[tid]:ssdata[tid+s];\n",
        "                __syncthreads();\n",
        "                sdata[tid] = (sdata[tid] <= sdata[tid + s])? sdata[tid]:sdata[tid+s];\n",
        "                __syncthreads();\n",
        "            }\n",
        "\n",
        "            __syncthreads();\n",
        "\n",
        "}\n",
        "        if(s == 0)\n",
        "        {\n",
        "            ssdata[0] = (sdata[0] <= sdata[n-1])? ssdata[0]:ssdata[n-1];\n",
        "            sdata[0] = (sdata[0] <= sdata[n-1])? sdata[0]:sdata[n-1];\n",
        "            __syncthreads();\n",
        "        }    \n",
        "    }\n",
        "       \n",
        "    if(tid == 0)\n",
        "    {\n",
        "        result_idx[blockIdx.x] = ssdata[0];\n",
        "        result_value[blockIdx.x] = sdata[0];     \n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "'''\n",
        ")\n",
        "\n",
        "\n",
        "def cluster_assignment_new(C, k):\n",
        "\n",
        "    n = k    \n",
        "    divider = k + 1 if(k % 2) else k        \n",
        "    while(divider % 2 == 0):\n",
        "        n = divider / 2\n",
        "        divider /= 2\n",
        "    n = np.int32(n)\n",
        "    n_gpu = cuda.mem_alloc(n.nbytes)\n",
        "    cuda.memcpy_htod(n_gpu, n)\n",
        "    \n",
        "    length = np.int32(k+1)\n",
        "    length_gpu = cuda.mem_alloc(length.nbytes)\n",
        "    cuda.memcpy_htod(length_gpu, length)\n",
        "    result_value = gpuarray.to_gpu(np.zeros((len(C)//k,),dtype = np.float32))\n",
        "    result_idx = gpuarray.to_gpu(np.zeros((len(C)//k,),dtype = np.int32))\n",
        "    C = gpuarray.to_gpu(C)\n",
        "\n",
        "    find_func_hybrid = find_minimum.get_function(\"find_min\")\n",
        "    find_func_hybrid(C, result_value, result_idx, length_gpu, n_gpu, block=(k, 1, 1),grid=(len(C) // k, 1))\n",
        "    cluster_assignment = np.zeros((len(result_idx),2))\n",
        "    \n",
        "    cluster_assignment[:,0] = result_idx.get()\n",
        "    cluster_assignment[:,1] = result_value.get()\n",
        "    return cluster_assignment"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS7pesKZy_eT"
      },
      "source": [
        "# matrix1 is dataset, matrix2 is centroids\n",
        "def get_x_square(matrix1):\n",
        "    \"\"\"\n",
        "      It can be interpolated that the dataset square need to calculate for only once!\n",
        "    \"\"\"\n",
        "    n = matrix1.shape[0] * matrix1.shape[1]\n",
        "    grid_dim = int(np.ceil(n / 1024))\n",
        "    n = np.int32(n)\n",
        "    n_gpu = cuda.mem_alloc(n.nbytes)\n",
        "    cuda.memcpy_htod(n_gpu, n)\n",
        "\n",
        "    x = matrix1.flatten().astype(np.float32)\n",
        "    \n",
        "    x_gpu = gpuarray.to_gpu(x)\n",
        "    x_func = get_square.get_function(\"x_square\")\n",
        "    \n",
        "    # we have a flexible block assignment\n",
        "    x_func(x_gpu, n_gpu, block=(1024,1,1), grid=(grid_dim,1))\n",
        "    return x_gpu # could be used as matrix1 in get_xy_square\n",
        "\n",
        "#数据点得分批去输\n",
        "def get_xy_square(x_gpu, matrix2, cluster_k, numSample, dim):\n",
        "    m = cluster_k * dim\n",
        "    # determining grid size\n",
        "    m = np.int32(m)\n",
        "    m_gpu = cuda.mem_alloc(m.nbytes)\n",
        "    cuda.memcpy_htod(m_gpu, m)\n",
        "    grid_dim = int(np.ceil(m / 1024))\n",
        "\n",
        "    y_gpu = matrix2.astype(np.float32)\n",
        "\n",
        "    # y_gpu = gpuarray.to_gpu(y)\n",
        "    y_func = get_square.get_function(\"y_square\")\n",
        "    \n",
        "    y_func(y_gpu, m_gpu, block=(1024,1,1), grid=(grid_dim,1))\n",
        "\n",
        "    self_sum1 = np.zeros((numSample, ), dtype = np.float32)\n",
        "    block_dim = len(self_sum1) // 1024 + 1\n",
        "    self_sum2 = np.zeros((cluster_k, ), dtype = np.float32)\n",
        "    \n",
        "    self_sum1_gpu = gpuarray.to_gpu(self_sum1)\n",
        "    self_sum2_gpu = gpuarray.to_gpu(self_sum2)\n",
        "    \n",
        "    numSample_np = np.int32(numSample)\n",
        "    numSample_gpu = cuda.mem_alloc(numSample_np.nbytes)\n",
        "    cuda.memcpy_htod(numSample_gpu, numSample_np)\n",
        "    \n",
        "    k = np.int32(cluster_k)\n",
        "    k_gpu = cuda.mem_alloc(k.nbytes)\n",
        "    cuda.memcpy_htod(k_gpu, k)\n",
        "    \n",
        "    dim = np.int32(dim)\n",
        "    dim_gpu = cuda.mem_alloc(dim.nbytes)\n",
        "    cuda.memcpy_htod(dim_gpu, dim)\n",
        "\n",
        "    result = np.zeros((cluster_k*numSample, ), dtype = np.float32)\n",
        "    block_dim_result = len(result) // 1024 + 1\n",
        "    \n",
        "    result_gpu = gpuarray.to_gpu(result)\n",
        "   \n",
        "    # optimization v1.0\n",
        "    sum_func_row = square_sum.get_function('sum_row_xy')\n",
        "\n",
        "    grid_dim_new = 500000 // 1024\n",
        "    sum_func_row(x_gpu, y_gpu, self_sum1_gpu, self_sum2_gpu, numSample_gpu, k_gpu, dim_gpu, block = (1024,1,1), grid = (grid_dim_new,1))\n",
        "    \n",
        "    sum_func_total = square_sum.get_function(\"sum_total\")\n",
        "    sum_func_total(self_sum1_gpu, self_sum2_gpu, result_gpu, k_gpu, numSample_gpu, block=(1024,1,1), grid=(block_dim_result,1))\n",
        "    \n",
        "    return result_gpu # result_gpu could be used for matrix3 in dis_computation\n",
        "\n",
        "\n",
        "# 计算与质心之间的距离\n",
        "def dis_computation(matrix1, matrix2, matrix3, orishape_matrix1):\n",
        "    \"\"\"matrix 1 is centroids, \n",
        "    matrix 2 is dataset.transpose, \n",
        "    matrix 3 is result\"\"\"\n",
        "    \n",
        "    matrix1 = matrix1.astype(np.float32)\n",
        "    matrix2 = matrix2.astype(np.float32)\n",
        "    \n",
        "    ldc = matrix2.shape[1]\n",
        "    m = matrix2.shape[1]\n",
        "    n = orishape_matrix1[0]\n",
        "\n",
        "    #C = matrix3.flatten()\n",
        "    #the above is matrix C\n",
        "    ldb = matrix2.shape[0]\n",
        "    k = matrix2.shape[0]\n",
        "    B_gpu = matrix1\n",
        "    #the above is matrix B\n",
        "\n",
        "    lda = matrix2.shape[1]\n",
        "    A_gpu = matrix2\n",
        "    # the above is matrix A\n",
        "    transa = 'n'\n",
        "    transb = 'n'\n",
        "    alpha = -2\n",
        "    beta = 1\n",
        "    #copy data into GPU\n",
        "    # A_gpu = gpuarray.to_gpu(A)\n",
        "    # B_gpu = gpuarray.to_gpu(B)\n",
        "    #C_gpu = gpuarray.to_gpu(C)\n",
        "    # computing matrix\n",
        "    h = cublas.cublasCreate()\n",
        "    cublas.cublasSgemm(h, transa, transb, m, n, k, alpha, A_gpu.gpudata, lda, B_gpu.gpudata, ldb, beta, matrix3.gpudata, ldc)\n",
        "    cublas.cublasDestroy(h)\n",
        "    \n",
        "    C = matrix3.get()\n",
        "    C = np.reshape(C, (n, m))\n",
        "    C = C.transpose() # 1484 * 10 or 494021 * 5\n",
        "    C = C.flatten()\n",
        "\n",
        "    return C\n",
        "\n",
        "\n",
        "def cluster_assignment(C, k=23):\n",
        "# 实质上这里也是在排序\n",
        "    if(len(C) == 1):\n",
        "        return np.array([C,0])\n",
        "    C = C.reshape((494021,k))\n",
        "    minDist = np.amin(C, axis = 1)\n",
        "    minDistIdx = np.argmin(C, axis = 1)\n",
        "    cluster_assignment = np.vstack((minDistIdx, minDist)).T\n",
        "    return cluster_assignment\n",
        "\n",
        "\n",
        "\n",
        "def sort_by_key_without_count(clusterAssment):\n",
        "    cluster = clusterAssment[:,0].astype(np.float32)\n",
        "    cluster_gpu = trtc.device_vector_from_numpy(cluster)\n",
        "    n = cluster_gpu.size()\n",
        "    index = trtc.device_vector(\"int32_t\", n)\n",
        "    trtc.Sequence(index)\n",
        "    trtc.Sort_By_Key(cluster_gpu, index)\n",
        "    index_cpu = index.to_host()\n",
        "    cluster_cpu = cluster_gpu.to_host()\n",
        "    return index_cpu, cluster_cpu\n",
        "\n",
        "\n",
        "def sort_gpu(index_cpu, cluster_cpu, dataset, k, placement):\n",
        "    cluster1 = cluster_cpu[0:250000].astype(np.float32)\n",
        "    cluster2 = cluster_cpu[250000:-1].astype(np.float32)\n",
        "    result1 = np.zeros((k-1,),dtype=np.float32)\n",
        "    result2 = np.zeros((k-1,),dtype=np.float32)\n",
        "    find_func = find.get_function(\"find_range\")\n",
        "    find_func(cuda.In(cluster1),cuda.Out(result1), block=(500,1,1),grid=(500,1))\n",
        "    find_func(cuda.In(cluster2),cuda.Out(result2), block=(500,1,1),grid=(500,1))\n",
        "    # 取置信值，这里的代码可以优化一下\n",
        "    # 如果数据量控制在25w以内效果最佳\n",
        "    for j in range(len(result2)):\n",
        "        if(result2[j] != 0):\n",
        "            result2[j] += 250000 # 分批处理，第一批计数从0开始，第二批从250000开始\n",
        "    for i in range(len(result2)-1):\n",
        "        if(result2[i] > result2[i+1]): # 消除异常值\n",
        "            result2[i] = 0\n",
        "    starting_points = [0]\n",
        "    for jj in range(len(result2)):\n",
        "        starting_points.append(max(result1[jj], result2[jj]))\n",
        "    starting_points.append(dataset.shape[0]+1)\n",
        "    data_in_cluster = []\n",
        "    start = int(starting_points[placement])\n",
        "    end = int(starting_points[placement+1])\n",
        "    data_in_cluster = dataset[index_cpu[start:end],:]\n",
        "    data_in_cluster = np.array(data_in_cluster)\n",
        "    return data_in_cluster\n",
        "\n",
        "\n",
        "\n",
        "def cluster_assignment_gpu(C):\n",
        "    C = C.astype(np.float32)\n",
        "    length = np.int32(C.shape[1])\n",
        "    length_gpu = cuda.mem_alloc(length.nbytes)\n",
        "    cuda.memcpy_htod(length_gpu, length)\n",
        "    result = np.zeros((C.shape[0],), dtype = np.float32)\n",
        "    # 找到距离最近的质心点\n",
        "    find_func = find.get_function(\"find_minimum\")\n",
        "    find_func(cuda.In(C),cuda.Out(result),length_gpu,block=(C.shape[1],1,1),grid=(C.shape[0],1))\n",
        "    \n",
        "    result_idx = np.argmin(C, axis = 1)    \n",
        "    cluster_assignment = np.zeros((len(result_idx),2))\n",
        "    cluster_assignment[:,0] = result_idx\n",
        "    cluster_assignment[:,1] = result\n",
        "    return cluster_assignment\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDdfrH3DzVCm"
      },
      "source": [
        "import pycuda\n",
        "\n",
        "# cpu的版本\n",
        "def euclDistance(vector1,vector2):\n",
        "    return np.sqrt(sum(np.power(vector2-vector1,2)))#power计算次方\n",
        "\n",
        "##初始化数据的中心点，k表示聚类中心数\n",
        "##随机生成k个聚类中心\n",
        "def initCentroids(dataset,k):\n",
        "    numSample,dim=dataset.shape\n",
        "    centroids=np.zeros((k,dim)).astype(np.float32)\n",
        "    for i in range(1,k+1):\n",
        "        #index=int(np.random.uniform(0,numSample))#随机生成数\n",
        "        index = int(i*10000)\n",
        "        centroids[i-1,:]=dataset[index,:]\n",
        "    return centroids\n",
        "\n",
        "##kmean算法\n",
        "def kmeans(dataset,k):\n",
        "    pycuda.tools.clear_context_caches()\n",
        "    numSample, dim = dataset.shape\n",
        "    #生成新的两列数组，保存聚类信息\n",
        "    # 第一列表示所属聚类中心，第二列表示与中心的误差\n",
        "    clusterAssment = np.zeros((numSample,2))#这里dtype就默认\n",
        "    clusterChanged = True\n",
        "\n",
        "## step1 初始化聚类中心\n",
        "    centroids=initCentroids(dataset,k)\n",
        "    storage = np.ones((numSample,))\n",
        "    storage = storage * k\n",
        "    itr = 0\n",
        "    dataset_transpose_gpu = gpuarray.to_gpu(dataset.T)\n",
        "    dataset_gpu_square = get_x_square(dataset)\n",
        "    orishape_matrix1 = centroids.shape\n",
        "\n",
        "    while (clusterChanged):\n",
        "        itr += 1\n",
        "        count = 0\n",
        "        for cnt in range(len(storage)):           \n",
        "            if(storage[cnt] != clusterAssment[cnt,0]):\n",
        "                count += 1\n",
        "                if(count > 10):\n",
        "                    clusterChanged = True\n",
        "                    break\n",
        "            else:\n",
        "                clusterChanged = False\n",
        "        \n",
        "        storage = clusterAssment[:,0]\n",
        "        #二重循环：对所有数据点，与k个聚类中心计算距离\n",
        "        #并保存标签与距离\n",
        "        matrix1 = gpuarray.to_gpu(centroids.flatten())\n",
        "        matrix2 = dataset_transpose_gpu\n",
        "        matrix3 = get_xy_square(dataset_gpu_square, matrix1, k, numSample, dim)\n",
        "        distance_mat = dis_computation(matrix1, matrix2, matrix3, orishape_matrix1)\n",
        "        # matrix1.gpudata.free()\n",
        "        \n",
        "        clusterAssment1 = clusterAssment # buffer\n",
        "        clusterAssment = cluster_assignment_new(distance_mat, k)\n",
        "\n",
        "\n",
        "## step4 循环结束后更新聚类中心\n",
        "        #index, cluster, count_dict = sort_by_key(clusterAssment)\n",
        "        #index, cluster = sort_by_key_without_count(clusterAssment)\n",
        "        #collection = []\n",
        "        for i in range(k):\n",
        "            comp = np.nonzero(clusterAssment[:,0] == i)[0] # 当前状态的聚类情况\n",
        "            comp1 = np.nonzero(clusterAssment1[:,0] == i)[0] # 上一状态的聚类情况\n",
        "            if(len(comp) == len(comp1) and (comp == comp1).all()):\n",
        "                 # 当前簇内元素没有改变？如果没有改变，下次聚类忽略该簇\n",
        "                continue\n",
        "                \n",
        "            #pointsInCluster = sort_gpu(index, cluster, dataset, k, i) \n",
        "            points_In_k_Cluster_Label=np.nonzero(clusterAssment[:,0]==i)[0]\n",
        "            pointsInCluster=dataset[points_In_k_Cluster_Label]\n",
        "            centroids[i, :] = np.mean(pointsInCluster, axis=0)\n",
        "            #centroids[i,:] = centroids_update(pointsInCluster, k)\n",
        "        \n",
        "        if(itr == 30):            \n",
        "            break\n",
        "    print(\"Iteration time is %.d\" % itr)\n",
        "    \n",
        "    ##循环结束，返回聚类中心和标签信息\n",
        "    return centroids,clusterAssment"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMcusnOpzfYG",
        "outputId": "784d861c-25e0-4a64-a037-d343ccf38706"
      },
      "source": [
        "if __name__==\"__main__\":\n",
        "    # print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
        "    # start=time.time()\n",
        "    ## load data\n",
        "    dataset=pd.read_csv('kdd_pre_final.csv',sep=',')\n",
        "    # 真实的标签\n",
        "    category_real = dataset.loc[:,[\"classification\"]]\n",
        " \n",
        "    dataset=dataset.iloc[:,:-1] \n",
        "    dataset=np.array(dataset)\n",
        "    \n",
        "    ##  k表示聚类中心数\n",
        "    k = 23\n",
        "    total_time = 0\n",
        "    times = 5\n",
        "    for _ in range(times):\n",
        "        start=time.time()\n",
        "        centroids,clusterAssment=kmeans(dataset,k)\n",
        "        end = time.time()\n",
        "        total_time += (end - start)\n",
        "    print('algorithm (for training) average time: %.2f seconds'%(total_time / times))\n",
        "    \n",
        "    category_real = np.array(category_real)\n",
        "    category = []\n",
        "    for i in range(dataset.shape[0]):\n",
        "        category.append(category_real[i][0])\n",
        "    category = np.array(category)\n",
        "    category_pre = np.array(clusterAssment[:,0], dtype = np.int32)\n",
        "    real = Counter(category)\n",
        "    pre = Counter(category_pre)\n",
        "    print(real)\n",
        "    print(pre)\n",
        "    real = real.most_common()\n",
        "    pre = pre.most_common()\n",
        "    for j in range(dataset.shape[0]):\n",
        "        for nn in range(k):\n",
        "            if(category[j] == real[nn][0]):\n",
        "                category[j] = int(pre[nn][0])\n",
        "    ARI = metrics.adjusted_rand_score(category, category_pre)\n",
        "    AMI = metrics.adjusted_mutual_info_score(category, category_pre)\n",
        "    print(\"The ARI value is {:.4f}\".format(ARI))\n",
        "    print(\"The AMI value is {:.4f}\".format(AMI))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration time is 28\n",
            "Iteration time is 28\n",
            "Iteration time is 28\n",
            "Iteration time is 28\n",
            "Iteration time is 28\n",
            "algorithm (for training) average time: 6.52 seconds\n",
            "Counter({5.0: 280790, 4.0: 107201, 0.0: 97278, 13.0: 2203, 15.0: 1589, 10.0: 1247, 9.0: 1040, 20.0: 1020, 8.0: 979, 7.0: 264, 17.0: 231, 6.0: 53, 1.0: 30, 11.0: 21, 19.0: 20, 14.0: 12, 22.0: 10, 2.0: 9, 12.0: 8, 18.0: 7, 16.0: 4, 3.0: 3, 21.0: 2})\n",
            "Counter({12: 253482, 11: 48529, 8: 38218, 5: 38215, 13: 37371, 10: 20457, 9: 11896, 2: 10479, 22: 8007, 19: 6941, 1: 5816, 7: 5393, 3: 5098, 0: 2316, 15: 1243, 14: 294, 21: 53, 17: 48, 4: 46, 6: 43, 20: 35, 18: 24, 16: 17})\n",
            "The ARI value is 0.7499\n",
            "The AMI value is 0.7345\n"
          ]
        }
      ]
    }
  ]
}